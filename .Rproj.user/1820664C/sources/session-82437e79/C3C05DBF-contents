#### PAUL BOCHTLER
#### 11.12.2021

#-----------------------------------------#
#### SET ENVIRONMENT                   ####
#-----------------------------------------#

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()

## empty potential rests from other scripts
rm(list = ls())

## load packages and install missing packages
require("pacman")
## define libraries to be loaded
packs <-
  c(
    'tidyverse',
    "janitor",
    'purrr',
    'rvest',
    'httr',
    'glue',
    'furrr',
    'quanteda',
    'quanteda.textstats',
    'jsonlite'
  )

p_load(char = packs)

source('00_functions.R')

folder <- "raw_data/html_index_clarin"
dir.create("raw_data")
dir.create(folder)

# pages <- 0:750
# future::plan('multisession', workers = 4)
# furrr::future_map(pages, scrape_clarin)

files <- list.files(folder, full.names = T)

future::plan('multisession', workers = 8)
data <- furrr::future_map_dfr(files, parse_clarin) %>%
  mutate(href = str_c('www.clarin.com', href)) %>%
  mutate(id = str_extract(href, "(?<=_0_).*(?=\\.html)")) %>%
  distinct()


folder <- "raw_data/html_page_clarin"
dir.create(folder)

folder_comments <- "raw_data/html_page_clarin_comments"
dir.create(folder)

future::plan('multisession', workers = 12)
# furrr::future_map_dfr(data$href, scrape_clarin_page, folder = folder, folder_comments = folder_comments)

files_page <- list.files(folder, full.names = T)
data_text <- future_map_dfr(files_page, parse_article_clarin)

files_comments <- list.files(folder_comments, full.names = T)
data_comments <-
  future_map_dfr(files_comments, parse_comments_clarin)

dir.create('clean_data')
write_csv(data_text, 'clean_data/full_text.csv')
write_csv(data_comments, 'clean_data/full_comments.csv')
write_csv(data, 'clean_data/base_data.csv')
